{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827586fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e8eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website URL\n",
    "url = \"http://quotes.toscrape.com\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a69300",
   "metadata": {},
   "source": [
    "Reason for choosing: This website is designed for web scraping practice. It contains structured data (quotes, authors, and tags), which makes it ideal for learning to extract and organize information. Scraping it is safe and ethical because it’s intended for educational purposes\n",
    "\n",
    "Data to Collect\n",
    "Quote Text: The text of each quote.\n",
    "Author: The person who said the quote.\n",
    "Tags: Categories or keywords associated with the quote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef70b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store scraped data\n",
    "quotes_list = []\n",
    "authors_list = []\n",
    "tags_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1733b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}  # <-- Make sure this is here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f368a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8209d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: http://quotes.toscrape.com\n",
      "Scraping: https://quotes.toscrape.com/page/2/\n",
      "Scraping: https://quotes.toscrape.com/page/3/\n",
      "Scraping: https://quotes.toscrape.com/page/4/\n",
      "Scraping: https://quotes.toscrape.com/page/5/\n",
      "Scraping: https://quotes.toscrape.com/page/6/\n",
      "Scraping: https://quotes.toscrape.com/page/7/\n",
      "Scraping: https://quotes.toscrape.com/page/8/\n",
      "Scraping: https://quotes.toscrape.com/page/9/\n",
      "Scraping: https://quotes.toscrape.com/page/10/\n",
      "✅ Finished scraping all pages!\n"
     ]
    }
   ],
   "source": [
    "while url:\n",
    "    print(\"Scraping:\", url)\n",
    "    \n",
    "    try:\n",
    "        # Add timeout and retries\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()  # Raise error if request fails\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        quotes = soup.find_all('div', class_='quote')\n",
    "        \n",
    "        for quote in quotes:\n",
    "            text = quote.find('span', class_='text').text.strip()\n",
    "            author = quote.find('small', class_='author').text.strip()\n",
    "            tags = [tag.text for tag in quote.find_all('a', class_='tag')]\n",
    "            \n",
    "            quotes_list.append(text)\n",
    "            authors_list.append(author)\n",
    "            tags_list.append(\", \".join(tags))\n",
    "        \n",
    "        # Find the next page\n",
    "        next_button = soup.find('li', class_='next')\n",
    "        if next_button:\n",
    "            next_page = next_button.find('a')['href']\n",
    "            url = \"https://quotes.toscrape.com\" + next_page\n",
    "        else:\n",
    "            url = None\n",
    "\n",
    "        # Be nice to the server\n",
    "        time.sleep(1)\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"⚠️ Timeout occurred. Retrying in 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "        continue  # retry the same URL\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"❌ Error:\", e)\n",
    "        break\n",
    "\n",
    "print(\"✅ Finished scraping all pages!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c127533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Quote': quotes_list,\n",
    "    'Author': authors_list,\n",
    "    'Tags': tags_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0013bea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete! Data saved as quotes_Babirye.csv\n"
     ]
    }
   ],
   "source": [
    "# Save as CSV\n",
    "data.to_csv('quotes_Babirye.csv', index=False)\n",
    "\n",
    "print(\"Scraping complete! Data saved as quotes_Babirye.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d626b",
   "metadata": {},
   "source": [
    "website Description: “Quotes to Scrape” contains famous quotes from various authors, organized by tags for easy browsing.\n",
    "\n",
    "Extracted Information: The dataset includes the text of the quote, the author, and tags associated with each quote.\n",
    "\n",
    "Format: Saved in CSV as quotes_Babirye.csv with three columns: Quote, Author, Tags.\n",
    "\n",
    "Challenges / Ethical Issues:\n",
    "\n",
    "The main challenge was navigating to collect all quotes across multiple pages.\n",
    "looping of the pages the kernel just kept running longer than expected\n",
    "\n",
    "Ethical consideration: this website is fully fully ethical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
